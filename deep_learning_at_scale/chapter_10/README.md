## Chapter 10: Data-Centric Scaling


### Exercise 1: Outlier Detection
To execute this exercise, use the following command:

```bash
deep-learning-at-scale chapter_10 od detect
```

### Data Augmentation Notebook

Refer to the notebook [augmentation_example.ipynb](./augmentation_example.ipynb) for examples of data augmentation techniques.

### Exercise 2: Handling Imbalance in a Multilabel Dataset

Refer to the notebook [weighted_sampler.ipynb](./weighted_sampler.ipynb) for techniques on handling imbalance in a multilabel dataset.

### Exercise 3: Loss Tricks to Find Noisy Samples
To train a data-diet model, use the following command:

```bash
deep-learning-at-scale chapter_10 data-diet train
```

Additionally, refer to the notebook [vis.ipynb](./vis.ipynb) to visualize the identified samples.

### Exercise 4: Confident Learning/Noisy Labels with Cleanlab

Explore the example of [Cleanlab](https://github.com/suneeta-mall/label_noise) for confident learning and handling noisy labels.

### Reference for Handling Disagreements from Multiple Annotators

You can find the implementation of Dawid Skene and its variants algorithms [here](https://github.com/sukrutrao/Fast-Dawid-Skene/blob/master/fast_dawid_skene/algorithms.py).

